# Site
repository: sproogen/resume-theme
favicon: images/favicon.ico
 
# Content configuration version 
version: 2

# Personal info
name: Tae Yeon Hwang
title: Junior Web Developer
email: gxd0214@gmail.com
# website: https://github.com/BigHwangTaeYeon/bighwangtaeyeon.github.io

# Dark Mode (true/false/never)
darkmode: never
 
# Social links
github_username:  BigHwangTaeYeon
# linkedin_username: 태연-황-b42900281

# About Section
about_title: About Me
# about_profile_image: images/profile.jpg
about_content: | # this will include new lines to allow paragraphs
  중소기업에서 백엔드 포지션으로 웹 서비스(SI/SM 업무)를 개발/배포/운영을 수행한 경험이 있습니다.<br><br>
  
  현재 SK 케미컬에서 400여명의 영업사원이, 활동을 기록하는 서비스를 개발/배포/운영하고 있습니다.<br>
  현재 운영중인 시스템은 기존 시스템의 일부를 가져와 재구성하고 확장한 시스템으로, 영업사원의 활동을 기록하고 통계를 확인할 수 있습니다.<br><br>
  타 시스템으로부터 데이터 일부는 실시간으로 연동하여 데이터 동시성을 맞추고 일부는 하루에 한번 배치를 돌리고 있습니다.<br>
  프로젝트 초반부터 서비스 운영까지 경험을 하고 있습니다.<br>

#  I am most skilled in: <mark> ○ AWS</mark> and <mark> ○ Eating Pizza</mark>

content:
  - title: Skill # Title for the section
    layout: list # Type of content section (list/text)
    content:
      - layout: left
        title: Backend
        description: |
            - Java, Spring Boot, Spring
            - Spring MVC, Spring Data JPA
            - Eclipse, Intellij
      - title: DevOps
        description: |
            - MySql
            - Jenkins, Git
      - title: Frontend
        description: |
            - JSP, Thymeleaf, Java Script

  - title: Projects
    layout: list
    content:
      - layout: left
      - title: 스페이스씨엘
        link: https://www.spacecl.com/
        sub_title: backend position
        caption: 2025.04 ~
        description: | # this will include new lines to allow paragraphs
          SK케미컬 영업 활동 시스템 개발<br>
          서비스 개발 기간 : 2025-04 ~ 2026-01<br>
          서비스 운영 기간 : 2026-01 ~<br>
          <br>
          RESTful API 개발<br>
          타 시스템과의 실시간 데이터 연동<br>
          데이터레이크를 통해 데이터 수집<br>
          Slow Query 성능 개선<br><br>

          기술스택 : Java, Spring boot, Jpa, Mybatis, MariaDB, AWS, BitBucket

      - title: 제이케이데이터시스템즈
        link: https://archive.gugak.go.kr/
        sub_title: full stack position
        caption: 2023.04 ~ 2023.12
        description: | # this will include new lines to allow paragraphs
          국악원 아카이브 시스템 개발/배포/운영<br>
          <br>
          빌드 배포 자동화<br>
          프록시 파일 생성 시, 문제 식별 및 개선<br>
          전자계약서 솔루션 연계<br>
          계약서 열람 및 다운로드 이력 AOP로 모듈화<br><br>
          기술스택 : Java, 전자정부 프레임워크, Mybatis, Cubrid, Git
  #        <br><br><br><br><br><br>
  #         <br><br>
  #         빌드 배포 자동화<br>
  #         프록시 파일 생성 시, 문제 식별 및 개선<br>
  #         전자계약서 솔루션 연계<br>
  # #          전자 계약서 연계, 운영 환경에서 NoSuchAlgorithmException 문제 해결<br>
  # #          전자정부 프레임워크, Cubrid 환경 개발 경험<br>
  #         검색엔진 뷰 테이블 분석<br>
  # #          공공데이터 품질관리 수준 평가<br>
  #         계약서 열람 및 다운로드 이력 AOP로 모듈화
  #         <br><br>
  #         기술 스택
  #           - Java, 전자정부 프레임워크, MyBatis, Cubrid
  #           - Jenkins, SVN
  
  - title: Experience # Title for the section
    layout: text # Type of content section (list/text)
    content: 
      <h4 style="font-weight:900;">활동 기록 시스템</h4><br>

      - 파일 업로드, Retry 전략<br>
      <mark> ○ 상황</mark> -
        (클라이언트 파일 업로드 > AIP를 통해 암호화 파일 생성 > S3 업로드 > AI로 데이터 전송)<br>
        여러 작업이 이루어지기에 유지보수를 위해 로깅이 필요하고 외부 통신으로 Retry 전략이 필요하다 판단.<br>
      <mark> ○ 실행</mark> -
        로깅 > 트랜잭션의 경계 수준을 나누기위해 로깅 전용 Facade 계층을 도입하고 새로운 트랜잭션을 생성하는 REQUIRES_NEW 속성을 사용.<br>
          이와 같은 파일 업로드 시스템이 많지 않아 AOP같은 기술은 오버 엔지니어링으로 판단하여 로깅 전용 클래스로 사용.<br>

        파일 관리 > 처음에는 파일을 메모리에 적재하여 동작시켰지만 성능 병목이 될 가능성으로<br>
          서버에 임시 저장 폴더에 파일 적재 후 해당 작업이 종료되면 삭제 처리.<br>

        Retry > (암호화, 업로드, 데이터 전송)Network, I/O로 인한 예외는 retry를 하며, @Recover를 통해 실패시 상태값을 로그에 남기고 파일 삭제<br>
      <mark> ○ 결과</mark> -
        파일 업로드 실패 시, 어느 지점이 문제가 되는지 추적이 가능하여 문제 해결에 대한 비용 절감.<br>
        시스템 간 연계가 항상 최상의 컨디션을 유지할 수 없기에 클라이언트에게 불편을 제공하지 않는 선에서 다시 시도하여 서비스를 제공<br>
      <br><br>

      - 외부 시스템으로 부터 대용량 데이터 수집<br>
      <mark> ○ 상황</mark> -
        SK 내부적으로 관리하는 데이터를 내부망의 데이터레이크에 적재되며, 데이터레이크가 제공하는 API를 통해 데이터를 제공받음.<br>
        (데이터를 가져오는 양은 테이블 기준 40개, 총 300만 로우). ** 바이트 기준으로도 나오면 좋을듯<br>
        1. read process write 모든 과정이 트랜잭션에 묶여 DB Lock 발생 가능성<br>
        2. 대용량 데이터를 메모리에 담아 처리하기에 OOM()발생 가능성 다분<br>
        3. 40가지 배치 작업을 병렬로 처리하여 전체 처리속도 단축 필요<br>
        4. 간헐적 Connection Time Out이 발생하여 Retry 전략 필요<br>
      <mark> ○ 실행</mark> -
        데이터레이크의 API를 호출하여 데이터를 메모리에 담고 가공 후 데이터 처리과정을 스프링 배치로 구현<br>
        1. 배치로 가져오는 데이터는 기존 시스템의 기준정보이기에 쓰기 작업이 없음.<br>
          또한 MariaDB를 사용하여 디폴트 Isolation Level이 REPEATABLE READ로 쓰기에 영향이 가지 않음.<br>
          추후 변경에 있어서 트랜잭션 경계를 Read 작업에는 Read only, Process 제외, Write에서는 기본 트랜잭션으로 나누는 것이 좋다 판단.<br>
        3. ThreadPoolTaskScheduler로 여러 스케쥴러를 동시에 처리하고 ExecutorService를 사용하여 배치의 잡을 병렬로 처리함.<br>
        4. Read Process Write 각 구간별로 재시도 전략을 도입하고 문제되는 구간을 파악하기 위해 Logging을 쌓아 Tracing 가능하게 처리<br>
        <br>
        
        데이터레이크는 데이터를 파일로 관리하며, 담당자와의 소통을 통해 API호출하는 방식에서 파일을 가져와 데이터베이스에 적재하는 프로세스로 변경 예정.<br>
      <mark> ○ 결과</mark> -
        파일로 관리하면 API를 통한 네트워크 비용, 메모리 부하, GC비용, 쓰레드 소모에 대한 부담을 줄일 수 있으며,<br>
        실패하여도 다시 호출하지 않고 파일을 통해 다시 시도하여 안정성과 1,2,3 문제 모두 해소가 가능.<br>
      <br><br>

      - 타 서비스와 데이터 정합성을 위한 실시간 배치-1<br>
      <mark> ○ 상황</mark> -
        활동기록 데이터를 타 서비스로 전송하여 데이터 동시성을 맞추는 작업을 스프링 배치로 작업하고 스케쥴러를 통해 1분 단위 배치 실행<br>

        1. 전송되는 데이터가 서비스의 핵심 데이터인 만큼 배치로 인해 락문제가 발생하여 성능 지연이 되지 않도록 처리 필요.<br>
        2. 잡 실패 시, 문제 영역을 Tracing할 수 있도록 로깅 필요.<br>
      <mark> ○ 실행</mark> -
        Read(데이터 조회) Process(검증 및 가공) Write(데이터 전송)로 구성하여 처리, 각 구간 별 실패 로그를 적재하여 관리하고 전송 결과를 상태값으로 관리.<br>
        1. 잡 실행 시, 작업 전체에 트랜잭션 보다는 구간 별로 Read에서 read-only Process 미반영 Write에서는 기본 트랜잭션으로 따로 처리.<br>
        2. 로그 적재는 AOP로 관심사 분리하여 오류 메세지 적재 및 수정/확장(유지보수)에 용이<br>
        
      <mark> ○ 결과</mark> -
        하루에 3천 건이상 쓰기작업이 이루어지는 테이블에 병목을 줄이게 됬으며,<br>
        전송 결과를 상태값으로 관리하여 각 서비스 문제 파악이 가능하고 전송 프로세스를 구간 별로 로깅하여 문제 지점과 문제점 파악에 용이<br>
      <br><br>

      - 타 서비스와 데이터 정합성을 위한 실시간 배치-1<br>
      <mark> ○ 상황</mark> -
        타 서비스로부터 데이터를 수신하여 데이터 동시성을 맞추는 API 개발<br>

        JSON 형태의 수신 데이터를 가공하여 수신 상태 값과 같이 적재하고 반환<br>
      <mark> ○ 실행</mark> -
      <mark> ○ 결과</mark> -
      <br><br>

      - CTE 풀스캔 문제<br>
      <mark> ○ 상황</mark> -
        (MariaDB를 사용) CTE에 조건을 걸지 않아 풀스캔이 되어 성능적으로 병목이 되는 문제 발생<br>
      <mark> ○ 실행</mark> -
        오라클의 경우 CTE에 조건을 걸지 않아도 옵티마이저가 최종 SELECT의 WHERE 조건이 CTE 내부로 조건을 푸시다운해주지만,<br>
        MariaDB에서는 각 CTE 내부에 조건을 직접 설정해야 풀스캔을 하지 않고 조건에 맞추어 인덱스가 사용됨.<br>
      <mark> ○ 결과</mark> -
        조회 시, 282s > 1s 로 개선<br>
      <br><br>

      - 복합키를 Primary Key and Unique로 변경<br>
      <mark> ○ 상황</mark> -
      <mark> ○ 실행</mark> -
      <mark> ○ 결과</mark> -
      <br><br>

      - 거래처 조회 쿼리 개선<br>
      <mark> ○ 상황</mark> -
        조인 연산에서 LEFT JOIN의 서브쿼리 두 개가 풀스캔을 하여 성능 병목을 발생<br>
      <mark> ○ 실행</mark> -
        인라인 뷰를 스칼라 쿼리로 변경<br>
        > 인라인 뷰는 조회된 전체 데이터가 임시테이블로 생성되어 ON절에서 연산하는 과정은 인덱스 사용이 불가능하여 풀스캔 진행.<br>
        > 스칼라 쿼리로 매 row 마다 조회에 필요한 적절한 인덱스 활용으로 전체 조회 비용 감소<br>
      <mark> ○ 결과</mark> -
        조회 시, 약 3s > 0.2s 로 개선<br><br>

      <h4 style="font-weight:900;">국악원 아카이브 시스템</h4><br>

      - 빌드 배포 자동화<br>
      <mark> ○ 상황</mark> - 기존 배포 방식은 FTP을 통해 컴파일된 .class 파일을 수동으로 서버에 업로드하는 방식으로 휴먼 에러와 많은 시간소요.<br>
        자동 배포화를 통해 개선 필요성 인지하여 도구로 흔히 사용되는 젠킨스와 깃랩을 비교.<br>
      <mark> ○ 실행</mark> - 많이 사용되야 많은 자료가 있을거라 판단, 추후 어떤 문제에 직면하면 해당 자료를 찾아 빠르고 쉽게 처리 가능할거라 판단.<br>
        a. 젠킨스는 오픈소스고, 깃랩은 유료로 상대적 부담감이 적은 젠킨스가 적절.<br>
        b. 다른 프로젝트들도 개선한다면 플러그인을 통해 다른 도구와의 연동이 유연한 젠킨스가 적절하다 판단.<br>
        c. 플러그인 사용으로 많은 메모리를 사용한다는 단점은 아카이브 시스템의 서버 환경에서 충분하다 판단.<br>
        위와 같은 근거로 주도적으로 젠킨스 도입을 추진하고 파이프라인을 Git clone > Build > Backup > Deploy > Tomcat restart 으로 구축.<br>
      <mark> ○ 결과</mark> - 실행과정에서 에러가 있으면 로그가 남아, 직관성이 뛰어남.<br>
        배포 과정의 실수와 시간을 단축, 젠킨스 빌드 시 추후 테스트 코드를 통해 어플리케이션 검증과 알람을 도입하면 더욱 안정성있는 도구로 사용이 가능할 것이라 생각.<br><br>

      - 프록시 파일 생성 문제 식별 및 개선<br>
      <mark> ○ 상황</mark> - 
        영상 및 음향 파일을 프록시 파일로 변환하는 과정에서 다수의 파일을 처리하는데 서버에 부하가 발생하는 현상 발생.<br>
        파일 변환 시, 폴링 방식으로 클라이언트에게 각 파일들의 진행률을 알려주는 로직에서 문제가 발생.<br>
        a. 10개의 파일을 변환한다면, 처음에 각 파일들이 변환중인지 완료된 상태인지 확인.<br>
        b. 각 변환중인 파일은 서버에 진행률을 가져오기 위해 요청, 이때 변환중인 다른 9개의 파일도 각각 모두 요청.<br>
        c. 한 파일을 체크 하는데 전체 파일 개수만큼 10번의 요청을 하여 진행할 수록 배수로 늘어나 시스템 부하가 발생.<br>
      <mark> ○ 실행</mark> - 
      처음에는 담당자들이 업무를 할 수 있도록 파일들을 배열로 묶어 상태를 확인하고 한번의 요청을 하는 방식으로 변경.<br>
      문제를 해결하고 아래와 같은 내용으로 웹소켓으로 개선을 고민<br>
      a. 로직 변경 또는 확장에서 이러한 실수가 줄어들 거란 판단.<br>
      b. 아카이브 서버의 특성상 파일의 크기가 크고 많은 작업으로 네트워크 사용량이 증가.<br>
      c. 다른 페이지에서 해당 페이지 접근 시 진행률 관련 이벤트 실행이 안되는 이슈.<br>
      d. 클라이언트는 데이터를 받기만 하면 되는 구조이기 때문에 적절하다 판단.<br>
      위와 같은 생각으로 스프링 프레임워크에서 지원하는 웹소켓으로 변경.<br>
      <mark> ○ 결과</mark> - TCP 연결 요청과 해제를 한 번만 하여 HTTP 헤더와 같이 불필요한 데이터를 주기적으로 전송하지 않고, 해당 페이지에 재접근 시 상태값 확인 가능.<br><br>

      - 전자계약서 솔루션 연계<br>
      <mark> ○ 상황</mark> - 프로세스는 담당자가 업체 프로그램을 통해 전자계약서 양식을 생성하고 태블릿 PC를 통해 국악원 고객과 계약을 진행.
        계약이 완료가 되면 아카이브 서버에 완료된 전자계약서를 업로드하고 관리자는 업로드 된 계약서를 확인.<br>
      <mark> ○ 실행</mark> - 계약 정보 테이블과 계약 상태 이력 테이블을 설계.<br>
        상태 이력 테이블은 계약 진행 상태에 따라 속성 값 들의 차이가 있어, 테이블을 세가지(시작, 진행, 완료)로 설계.<br>
        계약 상태 변경 시, 업체에서 제공하는 웹훅 이벤트를 통해 아카이브 서버를 호출.<br>
        상태값에 따라 동작을 달리 할 수 있도록 스테이트 패턴을 적용, 팩토리 메서드 패턴을 통해 해당 상태값의 객체 생성.<br>
      <mark> ○ 결과</mark> - 상태값에 따른 상세 정보 확인에 대한 요청사항은 없지만 추후에 설계한 데이터를 토대로 확인 가능.<br>
        또한 추가 작업이 필요하다면 스테이트 패턴을 통해 쉽게 파악 가능.<br><br>

      - 계약서 열람 및 다운로드 이력, 어노테이션 기반 AOP로 모듈화<br>
      <mark> ○ 상황</mark> - 계약서 관련 자료는 담당자에게 열람 권한을 부여하여 사용하도록 요청.<br>
      <mark> ○ 실행</mark> - 
      몇 안되는 분들의 권한이고 관리자 테이블에 권한관련 속성이 여러 개 있었기에 더 추가를 할지, 로그인 시 해당 조건에 맞는 유저에게만 세션에 역할을 추가할지 고민<br>
      다른 개발자가 권한 관련 작업 시 한군데서 확인을 하는 것이 좋다고 판단하여 첫번째로 진행.<br>
      간단히 필요한 부분에만 검증 코드를 작성하는 것보다 주도적으로 AOP로 구현하는 것이 좋다고 판단.<br>
      Pointcut을 패키지로 구분하려 하였지만 도메인 별로 구분되어있지 않기에 어노테이션 기반으로 구현.<br>
      <mark> ○ 결과</mark> - 하나의 모듈로 구성하여 유지보수성을 높이고 어노테이션 사용으로 재사용성을 높임.<br><br>


      # <h4 style="font-weight:900;">학습관리시스템</h4><br>

      # - 수직분할 파티셔닝을 통한 성능 최적화<br>
      # <mark> ○ 상황</mark> -
      # 강의 리스트 페이지는 강의 정보 20개 씩 출력.<br>
      # 강의 속성은 강의명, 강의 시간, 수강인원, 상세설명 등으로 구성.<br>
      # 상세설명은 text 타입의 큰 데이터를 요구하며 강의 리스트 페이지에서는 사용 되지 않음.<br>
      # 서버 스펙 CPU 4, MEM 8로 구성. 클라이언트 측 예상으로 월평균 200명이 수강.<br>
      # 강의 리스트 조회 시 상세 설명같은 큰 I/O 작업을 회원들이 같은 시간에 사용 할 경우, 병목현상 및 과부하 문제를 대비할 필요성을 인지.<br>
      # <mark> ○ 실행</mark> -
      # 강의 정보와 상세 정보를 하나의 테이블에 구성하여 상세 정보 컬럼 만 제외하여 조회하는 방식과 강의 정보와 상세 정보, 각 테이블로 분리하여 조회하는 방식으로 고민.<br>
      # 첫번째 방식은 모든 레코드를 읽고 제외하는 방식으로, 기존의 방식보다 실행 시간은 단축 되었지만 두번째 방식보다는 I/O 작업 비용이 더 발생할 것이라 판단.<br>
      # 강의 정보, 강의 상세 정보를 분리하여 테이블을 생성. 강의 리스트 페이지에서는 강의 정보 테이블 조회, 디테일 페이지에서는 강의와 상세 테이블을 조인 키워드를 통해 모든 정보 제공하여 개선.<br>
      # <mark> ○ 결과</mark> -
      # 하나의 테이블에서 모든 정보를 전달하는 방식보다 응답 시간 3배 단축, TPS 70배 향상으로 성능 최적화.<br><br>

      # - Synchronized 블록을 통한 동시성 제어<br>
      # <mark> ○ 상황</mark> - 
      # 수강 신청 시, 상품검증 > 수용인원 검증 > 수강신청의 로직으로 동작.<br>
      # 수용인원을 20명으로 지정 시 19명이 수강신청한 상태까지 신청이 가능, 20명이 신청한 이후로는 불가능.<br>
      # 19명이 신청한 상태에서 동시에 여러명이 신청한다, 수용인원을 초과할 수 있기에 동시성 제어를 해야겠다고 판단.<br>
      # <mark> ○ 실행</mark> - 
      # 구조는 Controller > Facade > Service > Repository, 수강 신청 로직은 상품검증 > 수용인원 검증 > 수강신청으로 구성.<br>
      # 기존에는 Lecture 엔터티안에 상품과 수용인원의 필드가 정의, LectureService에서 하나의 메서드로 상품 및 수용인원 검증.<br>
      # Facade 계층에서 수강신청 메서드 전체에 Synchronized 키워드를 사용하는 것은 오버헤드라 판단.<br>
      # LectureService에서 하나의 메서드로 상품 및 수용인원을 검증하던 것에서 상품 검증 메서드, 수용인원 검증 메서드로 분리.<br>
      # Facade 수강신청 메서드에서 Lecture 객체를 락으로 설정하고 Synchronized 블록을 생성하여 수용인원 검증 후 수강 신청으로 구현.<br>
      # <mark> ○ 결과</mark> - 타이밍 상관 없이 안정적으로 수강 신청에 대한 수용인원 검증이 이루어지도록 구현.<br><br>

      # - 반정규화를 통한 쿼리 복잡도와 시간 복잡도 최적화<br>
      # <mark> ○ 상황</mark> - 
      # 관리자가 프로젝트를 생성하면 회원들이 해당 프로젝트를 신청 가능.<br>
      # 관리자는 신청한 회원들을 대상으로 신청 상태값(신청, 승인, 거절)을 변경하고 팀 생성과 리더, 팀원을 지정.<br>
      # 정규화과정을 통해 프로젝트 테이블, 신청 테이블, 팀 테이블, 회원 테이블로 구성.<br>
      # 로직은 a. 회원 승인 또는 거절 처리 b. 팀 생성 c. 회원 등록 또는 변경 으로 구성.<br>
      # c 로직은 승인된 회원들의 반복문, 생성된 팀을 위한 반복문, 요청 데이터를 반복문으로 회원 정보 변경.<br>
      # 테이블과 코드에 대한 복잡도가 높고 시간복잡도도 O(n^3)로 개선 필요하다 판단.<br>
      # <mark> ○ 실행</mark> - 
      # a. 팀을 생성하며 id를 요청 데이터 객체에 저장. 승인 회원 반복문, 회원 정보 반복문으로 O(n^2)로 변경했지만 다른 조회에서도 테이블 복잡성으로 반정규화를 진행.<br>
      # b. 테이블 구성을 프로젝트, 신청, 팀, 회원에서 프로젝트, 신청 및 회원, 팀으로 변경.<br>
      # 로직은 a. 회원 승인 또는 거절 처리 b. 팀 생성 c. 회원 등록 또는 변경 으로 구성에서 a. 팀 생성 b. 회원 상태값 변경, 승인된 회원들 중 등록 또는 변경으로 구성.<br>
      # 생성된 팀 반복문안에서 승인된 회원들만 필터링하여 상태값을 변경하고 회원 정보 변경.<br>
      # <mark> ○ 결과</mark> - 시간 복잡도 O(n^3)에서 O(n^2)으로 개선하고 쿼리 최적화 진행.<br><br>

      # - 아키텍쳐 구조 변경<br>
      # <mark> ○ 상황</mark> - 
      # 모든 직원이 SI 업무를 주로 맡지만 SM 업무로 인해 시간을 많이 소비하는 것을 인지.<br>
      # 백엔드 기존 구조와 방식은 Controller > Service > ServiceImpl > DAO, 비즈니스 로직은 Controller 에 작성.<br>
      # 모든 요청을 Controller 2개 VO 1개로 처리하여 구조가 단순하고 기존에 작업자들에게 익숙한 방법.<br>
      # 유지보수 업무 수행 중 디버깅 시 Vo안에 수십 개의 필드가 정의되어 업무 처리하기에 불편하고,<br>
      # 파일 업로드 경로를 변경하는 업무에서는, 공통적으로 사용 되는 경로 값이 제각기 정의되어 모든 로직에서 변경이 필요하여 주도적으로 전체 구조를 재구성 할 필요가 있다고 판단.<br>
      # <mark> ○ 실행</mark> - 
      # a. 기존 구조를 가져가며 계층 별 역할을 나누고 Util 파일로 공통 소스를 개발하여 재사용성을 고려하는 방법을 생각<br>
      # 기존 구조는 단순하고 익숙한 방법이지만 주로 작업하는 나의 입장에서는 JPA를 사용하는 것이 개발 속도에 도움된다고 판단.<br>
      # a-1. 기존 작업자는 NextJS에서 ORM 사용 경험 보유.<br>
      # a-2. 동적 쿼리는 QueryDSL 도 있지만 러닝커브로 인해 익숙한 MyBatis 를 선택.<br>
      # 하여 Repository 계층을 도입하고  Service, Repository, JPA - MyBatis 구조로 개선.<br>
      # b. 주요 비즈니스 로직을 담고 있는 Service 또한 Controller와 디커플링되어야 한다고 생각.<br>
      # b-1. 컨트롤러에서 여러 서비스를 호출 시, 이전처럼 컨트롤러에 로직이 발생할 것이라 생각.<br>
      # b-2. 서비스를 재사용하기 위해 서비스 간의 호출은 순환참조가 발생.<br>
      # 하여 Facade 계층을 도입하여 Controller와 Service를 디커플링.<br>
      # <mark> ○ 결과</mark> - Controller, Facade, Service, Repository, JPA - MyBatis로 구분하여 단일 책임 원칙을 적용한 구조로 변경.<br>
      # SI 업무를 수행하는데 있어서 기존의 방식보다 다소 시간이 걸릴 수있지만, 추후 SM 업무를 위해 더 나은 방식이라 생각.<br><br>


      # - layout: text
      # description: <h4 style="font-weight:900;">학습관리시스템</h4>
      #   <h4>수직분할 파티셔닝을 통한 성능 최적화</h4><br>
      #   <mark> ○ 상황</mark> -
      #   강의 리스트 페이지는 강의 정보 20개 씩 출력.<br>
      #   강의 속성은 강의명, 강의 시간, 수강인원, 상세설명 등으로 구성.<br>
      #   상세설명은 text 타입의 큰 데이터를 요구하며 강의 리스트 페이지에서는 사용 되지 않음.<br>
      #   서버 스펙 CPU 4, MEM 8로 구성. 클라이언트 측 예상으로 월평균 200명이 수강.<br>
      #   강의 리스트 조회 시 상세 설명같은 큰 I/O 작업을 회원들이 같은 시간에 사용 할 경우, 병목현상 및 과부하 문제를 대비할 필요성을 인지.<br>
      #   <mark> ○ 실행</mark> -
      #   강의 정보와 상세 정보를 하나의 테이블에 구성하여 상세 정보 컬럼 만 제외하여 조회하는 방식과 강의 정보와 상세 정보, 각 테이블로 분리하여 조회하는 방식으로 고민.<br>
      #   첫번째 방식은 모든 레코드를 읽고 제외하는 방식으로, 기존의 방식보다 실행 시간은 단축 되었지만 두번째 방식보다는 I/O 작업 비용이 더 발생할 것이라 판단하여 강의 정보, 강의 상세 정보로 분리하여 테이블을 생성.<br>
      #   강의 리스트 페이지에서는 강의 정보 테이블에서 조회하며 디테일 페이지에서는 강의와 상세 테이블을 조인 키워드를 통해 모든 정보 제공하여 개선.<br>
      #   <mark> ○ 결과</mark> -
      #   하나의 테이블에서 모든 정보를 전달하는 방식보다 응답 시간 3배 단축, TPS 70배 향상으로 성능 최적화.

      # - layout: text
      # #   title: ○ Zoom API 토큰 관리
      # #   # sub_title: Senior Network System Administrator
      # #   # caption: November 2017 - Present
      # #   # quote: >
      # #   #   배포 시, FTP를 통해 class 파일을 직접 올리는 방식을 사용해왔습니다. 휴먼 에러와 개발 비용이 많이 소모되는 것을 확인했습니다.
      # #   description: | # this will include new lines to allow paragraphs
      # #       <mark> ○ 상황</mark> : Zoom API를 통해 Token을 생성하고 Room 생성 시, 해당 토큰을 전달해야합니다.<br>
      # #         해당 토큰은 30분간 유효하며 재사용을 위해 어떻게 관리하는 것이 좋은 방법인지 고민이었습니다.<br>
      # #       <mark> ○ 실행</mark> : SSD 보다 MEM에 관리하는 것이 좋다고 판단하였고,<br>
      # #         토큰 필드 값들을 inner class로 설계하여 외부에서 변경이 불가능하며 정적으로 선언하여 메모리를 관리하며 재사용하였습니다.<br>
      # #       <mark> ○ 결과</mark> : 데이터베이스 커넥션을 사용하지 않고, I/O 작업을 하지 않아도 토큰을 재사용할 수 있었습니다.
      # # - title: ○ 외부 API 사용 시, 원자성 보장
      # #   description: | # this will include new lines to allow paragraphs
      # #       <mark> ○ 상황</mark> : 외부 API를 통해 연계작업을 하나의 트랜잭션 경계에 묶어 사용해도 원자성이 보장되지 않는 문제가 있었습니다.<br>
      # #         외부 API를 통해 결제 취소를 하고 해당 결제 취소에 대한 정보를 받아 후 처리하는 작업에서 Exception 이 발생해도 결제 취소에 대한 롤백이 되지 않는 문제가 있었습니다<br>
      # #       <mark> ○ 실행</mark> : 상태값에 대한 통신을 따로 구현할 수 없기에 예외 처리를 해당 결과값에 대해 따로 데이터베이스에 저장해 두는 방식으로 결정하였습니다<br>
      # #       <mark> ○ 결과</mark> : 원자성 보장에 대한 처리가 되지는 않지만, 에외가 발생해도 이후에 대처가 가능하게 되었습니다.
      # # - title: 수직분할 파티셔닝을 통한 성능 최적화
      #   description: | # this will include new lines to allow paragraphs
      #       <h4>수직분할 파티셔닝을 통한 성능 최적화</h4><br>
      #       <mark> ○ 상황</mark> : 
      #       강의 리스트 페이지는 강의 정보 20개 씩 출력.<br>
      #       강의 속성은 강의명, 강의 시간, 수강인원, 상세설명 등으로 구성.<br>
      #       상세설명은 text 타입의 큰 데이터를 요구하며 강의 리스트 페이지에서는 사용 되지 않음.<br>
      #       서버 스펙 CPU 4, MEM 8로 구성. 클라이언트 측 예상으로 월평균 200명이 수강.<br>
      #       강의 리스트 조회 시 상세 설명같은 큰 I/O 작업을 회원들이 같은 시간에 사용 할 경우, 병목현상 및 과부하 문제를 대비할 필요성을 인지.<br>
      #       <mark> ○ 실행</mark> : 
      #       강의 정보와 상세 정보를 하나의 테이블에 구성하여 상세 정보 컬럼 만 제외하여 조회하는 방식과 강의 정보와 상세 정보, 각 테이블로 분리하여 조회하는 방식으로 고민.<br>
      #       첫번째 방식은 모든 레코드를 읽고 제외하는 방식으로, 기존의 방식보다 실행 시간은 단축 되었지만 두번째 방식보다는 I/O 작업 비용이 더 발생할 것이라 판단하여 강의 정보, 강의 상세 정보로 분리하여 테이블을 생성.<br>
      #       강의 리스트 페이지에서는 강의 정보 테이블에서 조회하며 디테일 페이지에서는 강의와 상세 테이블을 조인 키워드를 통해 모든 정보 제공하여 개선.<br>
      #       <mark> ○ 결과</mark> : 
      #       하나의 테이블에서 모든 정보를 전달하는 방식보다 응답 시간 3배 단축, TPS 70배 향상으로 성능 최적화.
      # - title: Synchronized 블록을 통한 동시성 제어
      #   description: | # this will include new lines to allow paragraphs
      #       <mark> ○ 상황</mark> : 
      #       수강 신청 시, 상품검증 > 수용인원 검증 > 수강신청의 로직으로 동작.<br>
      #       수용인원을 20명으로 지정 시 19명이 수강신청한 상태까지 신청이 가능, 20명이 신청한 이후로는 불가능.<br>
      #       19명이 신청한 상태에서 동시에 여러명이 신청한다, 수용인원을 초과할 수 있기에 동시성 제어를 해야겠다고 판단.<br>
      #       <mark> ○ 실행</mark> : 
      #       구조는 Controller > Facade > Service > Repository, 수강 신청 로직은 상품검증 > 수용인원 검증 > 수강신청으로 구성.<br>
      #       기존에는 Lecture 엔터티안에 상품과 수용인원의 필드가 정의, LectureService에서 하나의 메서드로 상품 및 수용인원 검증.<br>
      #       Facade 계층에서 수강신청 메서드 전체에 Synchronized 키워드를 사용하는 것은 오버헤드라 판단.<br>
      #       LectureService에서 하나의 메서드로 상품 및 수용인원을 검증하던 것에서 상품 검증 메서드, 수용인원 검증 메서드로 분리.<br>
      #       Facade 수강신청 메서드에서 Lecture 객체를 락으로 설정하고 Synchronized 블록을 생성하여 수용인원 검증 후 수강 신청으로 구현.<br>
      #       <mark> ○ 결과</mark> : 
      #       타이밍 상관 없이 안정적으로 수강 신청에 대한 수용인원 검증이 이루어지도록 구현.<br>
      # - title: 반정규화를 통한 쿼리 복잡도와 시간 복잡도 최적화
      #   description: | # this will include new lines to allow paragraphs
      #       <mark> ○ 상황</mark> : 
      #       관리자가 프로젝트를 생성하면 회원들이 해당 프로젝트를 신청 가능.<br>
      #       관리자는 신청한 회원들을 대상으로 신청 상태값(신청, 승인, 거절)을 변경하고 팀 생성과 리더, 팀원을 지정.<br>
      #       정규화과정을 통해 프로젝트 테이블, 신청 테이블, 팀 테이블, 회원 테이블로 구성.<br>
      #       로직은 a. 회원 승인 또는 거절 처리 b. 팀 생성 c. 회원 등록 또는 변경 으로 구성.<br>
      #       c 로직은 승인된 회원들의 반복문, 생성된 팀을 위한 반복문, 요청 데이터를 반복문으로 회원 정보 변경.<br>
      #       테이블과 코드에 대한 복잡도가 높고 시간복잡도도 O(n^3)로 개선 필요하다 판단.<br>
      #       <mark> ○ 실행</mark> : 
      #       a. 팀을 생성하며 id를 요청 데이터 객체에 저장하여 승인 회원 반복문, 회원 정보 반복문으로 O(n^2)로 변경했지만 다른 조회에서도 테이블의 복잡성을 느껴 반정규화를 진행.<br>
      #       b. 테이블 구성을 프로젝트, 신청, 팀, 회원에서 프로젝트, 신청 및 회원, 팀으로 변경.<br>
      #       로직은 a. 회원 승인 또는 거절 처리 b. 팀 생성 c. 회원 등록 또는 변경 으로 구성에서 a. 팀 생성 b. 회원 상태값 변경, 승인된 회원들 중 등록 또는 변경으로 구성.<br>
      #       생성된 팀 반복문안에서 승인된 회원들만 필터링하여 상태값을 변경하고 회원 정보 변경.<br>
      #       <mark> ○ 결과</mark> : 시간 복잡도 O(n^3)에서 O(n^2)으로 개선하고 쿼리 최적화 진행.
      # - title: 아키텍쳐 구조 변경
      #   description: | # this will include new lines to allow paragraphs
      #       <mark> ○ 상황</mark> : 
      #       모든 직원이 SI 업무를 주로 맡지만 SM 업무로 인해 시간을 많이 소비하는 것을 인지.<br>
      #       백엔드 기존 구조와 방식은 Controller > Service > ServiceImpl > DAO, 비즈니스 로직은 Controller 에 작성.<br>
      #       모든 요청을 Controller 2개 VO 1개로 처리하여 구조가 단순하고 기존에 작업자들에게 익숙한 방법.<br>
      #       유지보수 업무 수행 중 디버깅 시 Vo안에 수십 개의 필드가 정의되어 업무 처리하기에 불편하고,<br>
      #       파일 업로드 경로를 변경하는 업무에서는, 공통적으로 사용 되는 경로 값이 제각기 정의되어 모든 로직에서 변경이 필요하여 주도적으로 전체 구조를 재구성 할 필요가 있다고 판단.<br>
      #       <mark> ○ 실행</mark> : 
      #       a. 기존 구조를 가져가며 계층 별 역할을 나누고 Util 파일을 활성화하여 재사용성을 고려하는 방법을 생각, 단순하고 익숙한 방법이지만 주로 작업하는 나의 입장에서는 JPA를 사용하는 것이 개발 속도에 도움된다고 판단.<br>
      #       또한 기존 작업자는 NextJS에서 ORM 사용 경험 보유.<br>
      #       동적 쿼리는 QueryDSL 도 있지만 러닝커브로 인해 익숙한 MyBatis 를 선택.<br>
      #       b. 주요 비즈니스 로직을 담고 있는 Service 또한 Controller와 디커플링되어야 한다고 생각.<br>
      #       서비스를 재사용하기 위해 서비스 간의 호출은 순환참조가 발생.<br>
      #       컨트롤러에서 여러 서비스를 호출 시, 이전처럼 컨트롤러에 로직이 발생할 것이라 생각.<br>
      #       하여 Facade 계층을 도입하여 Controller와 Service를 디커플링.<br>
      #       <mark> ○ 결과</mark> : Controller, Facade, Service, Repository, JPA - MyBatis로 구분하여 단일 책임 원칙을 적용한 구조로 변경.<br>
      #         SI 업무를 수행하는데 있어서 기존의 방식보다 다소 시간이 걸릴 수있지만, 추후 SM 업무를 위해 더 나은 방식이라 생각.<br>

      # - layout: top
      #   title: <h4 style="font-weight:900;">국악원 아카이브 시스템</h4>

      # - title: 빌드 배포 자동화
      #   description: | # this will include new lines to allow paragraphs
      #       <mark> ○ 상황</mark> : 기존 배포 방식은 FTP을 통해 컴파일된 .class 파일을 수동으로 서버에 업로드하는 방식으로 휴먼 에러와 많은 시간소요.<br>
      #         자동 배포화를 통해 개선 필요성 인지하여 도구로 흔히 사용되는 젠킨스와 깃랩을 비교.<br>
      #       <mark> ○ 실행</mark> : 많이 사용되야 많은 자료가 있을거라 판단, 추후 어떤 문제에 직면하면 해당 자료를 찾아 빠르고 쉽게 처리 가능할거라 판단.<br>
      #         a. 젠킨스는 오픈소스고, 깃랩은 유료로 상대적 부담감이 적은 젠킨스가 적절.<br>
      #         b. 다른 프로젝트들도 개선한다면 플러그인을 통해 다른 도구와의 연동이 유연한 젠킨스가 적절하다 판단.<br>
      #         c. 플러그인 사용으로 많은 메모리를 사용한다는 단점은 아카이브 시스템의 서버 환경에서 충분하다 판단.<br>
      #         위와 같은 근거로 주도적으로 젠킨스 도입을 추진하고 파이프라인을 Git clone > Build > Backup > Deploy > Tomcat restart 으로 구축.<br>
      #       <mark> ○ 결과</mark> : 실행과정에서 에러가 있으면 로그가 남아, 직관성이 뛰어남.<br>
      #         배포 과정의 실수와 시간을 단축, 젠킨스 빌드 시 추후 테스트 코드를 통해 어플리케이션 검증과 알람을 도입하면 더욱 안정성있는 도구로 사용이 가능할 것이라 생각.
      # - title: 프록시 파일 생성 문제 식별 및 개선
      #   description: | # this will include new lines to allow paragraphs
      #       <mark> ○ 상황</mark> : 
      #         영상 및 음향 파일을 프록시 파일로 변환하는 과정에서 다수의 파일을 처리하는데 서버에 부하가 발생하는 현상 발생.<br>
      #         파일 변환 시, 폴링 방식으로 클라이언트에게 각 파일들의 진행률을 알려주는 로직에서 문제가 발생.<br>
      #         a. 10개의 파일을 변환한다면, 처음에 각 파일들이 변환중인지 완료된 상태인지 확인.<br>
      #         b. 각 변환중인 파일은 서버에 진행률을 가져오기 위해 요청, 이때 변환중인 다른 9개의 파일도 각각 모두 요청.<br>
      #         c. 한 파일을 체크 하는데 전체 파일 개수만큼 10번의 요청을 하여 진행할 수록 배수로 늘어나 시스템 부하가 발생.<br>
      #       <mark> ○ 실행</mark> : 
      #       처음에는 담당자들이 업무를 할 수 있도록 파일들을 배열로 묶어 상태를 확인하고 한번의 요청을 하는 방식으로 변경.<br>
      #       문제를 해결하고 아래와 같은 내용으로 웹소켓으로 개선을 고민<br>
      #       a. 로직 변경 또는 확장에서 이러한 실수가 줄어들 거란 판단.<br>
      #       b. 아카이브 서버의 특성상 파일의 크기가 크고 많은 작업으로 네트워크 사용량이 증가.<br>
      #       c. 다른 페이지에서 해당 페이지 접근 시 진행률 관련 이벤트 실행이 안되는 이슈.<br>
      #       d. 클라이언트는 데이터를 받기만 하면 되는 구조이기 때문에 적절하다 판단.<br>
      #       위와 같은 생각으로 스프링 프레임워크에서 지원하는 웹소켓으로 변경.<br>
      #       <mark> ○ 결과</mark> : TCP 연결 요청과 해제를 한 번만 하여 HTTP 헤더와 같이 불필요한 데이터를 주기적으로 전송하지 않고, 해당 페이지에 재접근 시 상태값 확인 가능.
      # - title: 전자계약서 솔루션 연계
      #   description: | # this will include new lines to allow paragraphs
      #       <mark> ○ 상황</mark> : 프로세스는 담당자가 업체 프로그램을 통해 전자계약서 양식을 생성하고 태블릿 PC를 통해 국악원 고객과 계약을 진행.
      #         계약이 완료가 되면 아카이브 서버에 완료된 전자계약서를 업로드하고 관리자는 업로드 된 계약서를 확인.<br>
      #       <mark> ○ 실행</mark> : 계약 정보 테이블과 계약 상태 이력 테이블을 설계.<br>
      #         상태 이력 테이블은 계약 진행 상태에 따라 속성 값 들의 차이가 있어, 테이블을 세가지(시작, 진행, 완료)로 설계.<br>
      #         계약 상태 변경 시, 업체에서 제공하는 웹훅 이벤트를 통해 아카이브 서버를 호출.<br>
      #         상태값에 따라 동작을 달리 할 수 있도록 스테이트 패턴을 적용, 팩토리 메서드 패턴을 통해 해당 상태값의 객체 생성.<br>
      #       <mark> ○ 결과</mark> : 상태값에 따른 상세 정보 확인에 대한 요청사항은 없지만 추후에 설계한 데이터를 토대로 확인 가능.<br>
      #         또한 추가 작업이 필요하다면 스테이트 패턴을 통해 쉽게 파악 가능.
      # - title: 계약서 열람 및 다운로드 이력, 어노테이션 기반 AOP로 모듈화
      #   description: | # this will include new lines to allow paragraphs
      #       <mark> ○ 상황</mark> : 계약서 관련 자료는 담당자에게 열람 권한을 부여하여 사용하도록 요청.<br>
      #       <mark> ○ 실행</mark> : 
      #       몇 안되는 분들의 권한이고 관리자 테이블에 권한관련 속성이 여러 개 있었기에 더 추가를 할지, 로그인 시 해당 조건에 맞는 유저에게만 세션에 역할을 추가할지 고민<br>
      #       다른 개발자가 권한 관련 작업 시 한군데서 확인을 하는 것이 좋다고 판단하여 첫번째로 진행.<br>
      #       간단히 필요한 부분에만 검증 코드를 작성하는 것보다 주도적으로 AOP로 구현하는 것이 좋다고 판단.<br>
      #       Pointcut을 패키지로 구분하려 하였지만 도메인 별로 구분되어있지 않기에 어노테이션 기반으로 구현.<br>
      #       <mark> ○ 결과</mark> : 하나의 모듈로 구성하여 유지보수성을 높이고 어노테이션 사용으로 재사용성을 높임.

  # - title: Side Projects
  #   layout: list
  #   content:
  #     - layout: left
  #       title: 멍모
  #       link: https://github.com/BigHwangTaeYeon/MungMo
  #       caption: 2024.06.21 ~ 2024.09.30
  #       quote: >
  #         견주 모임 서비스 개발 (백엔드 개발)
  #       description: | # this will include new lines to allow paragraphs
  #         Restful API 구현<br>
  #         MSA 아키텍쳐 구축<br>
  #         kafka connector(debezium)를 활용하여 cdc를 통해 데이터 동기화<br>
  #         Kafka를 활용한 채팅 서비스 메시지 디커플링<br>
  #         DDD(Domain Driven Design)<br>
  #         <br>
  #         기술 스택<br>
  #           Java, Spring Boot, Spring Cloud, WebSocket<br>
  #           MySQL, MongoDB, kafka
  #         <br><br>

  #         <mark> ○ 상황</mark> : 
  #           서비스간의 디커플링을 위해 데이터베이스를 분리하였고, 데이터 동기화가 필요했습니다.<br>
  #           또한 동기화를 통해 얻은 데이터로 모두 처리해도 될까? 라는 궁금증이 생겼습니다.<br>
  #         <mark> ○ 실행</mark> : 
  #           비동기, 분산처리, 스트리밍의 장점을 가진 카프카를 택하였고, 카프카 커넥터를 통해 동기화를 구축했습니다.<br>
  #           하지만 confluent로는 기존 데이터의 변경감지를 못하고 bulk는 오버헤드라 생각되어 debezium으로 설정하였습니다.<br>
  #           데이터 정합성이 중요한 로직에서는 FeignClient 를 이용해 통신을 하였습니다.<br>
  #         <mark> ○ 결과</mark> : 
  #           cdc를 통해 데이터를 동기화하여 다른 데이터베이스의 데이터를 가져올 수 있었고,<br>
  #           데이터 정합성이 중요한 매너 점수 연산에서 통신으로 데이터를 가져와서 처리하였습니다.<br>

  #         <mark> ○ 상황</mark> : 
  #           채팅 서비스의 메세지 처리를, 카프카를 통해 TPS를 높일 수 있다는 자료를 보게 되었습니다.<br>
  #           컨슘에서 메세지를 받고 로직처리는 스프링에서 동작하는데, 과연 자료의 결과대로 가져올지 궁금했습니다.<br>
  #         <mark> ○ 실행</mark> : 
  #           빠른 응답성이 필요한 메세지 출력은 웹소켓에서 처리하고, consumer가 메세지를 받으면 여러 로직을 처리할 수 있도록 구현하였습니다.<br>
  #           Jmeter로 부하테스트를 하면, 카프카 사용 시 180/s 미사용 시 187/s로 자료와 결과가 달라 전제조건을 다시 확인해봤지만 결과는 같았습니다.<br>
  #         <mark> ○ 결과</mark> : 
  #           그 자료는 이력서를 위한 가짜자료라는 것으로 확인되고, 카프카라는 작업을 거치기 때문에 미세한 차이로 더 낮은 성능을 보이는 것으로 이해했습니다.<br>
  #           결론은 디커플링을 위해 사용한다로 이해하고, 카프카를 통해 어드민 서비스에서 알람 처리로 마무리를 지었습니다.<br>

  #         <mark> ○ 상황</mark> : 
  #           유저 매너 점수를 반영하는 기능은 언제든 정책이 바뀌면 쉽게 반영될 수 있도록 설계가 필요했습니다.<br>
  #         <mark> ○ 실행</mark> : 
  #           확장성을 고려해서 추상화하여 기능을 구현하고, 도메인 비즈니스 로직의 기능과 객체와의 느슨한 결합도가 필요하여 바로 생각난 것이 Spring DI 였고,
  #           Factory Method Pattern 을 통해 클라이언트 객체와 느슨한 결합을 완성하였습니다.<br>
  #         <mark> ○ 결과</mark> : 
  #           정책이 변경이 되어도 추상화를 통해 새로운 구현체를 바로 생성할 수 있고, 클라이언트 객체가 아닌 팩토리에서 하나만 변경해주면 됩니다. 이로써 객체지향 설계원칙, OCP 를 지켜낼 수 있었습니다.<br>
  #           ![FactoryMethodPattern](./FactoryMethodPattern.jpg)

  #         <mark> ○ 상황</mark> : 
  #           서비스간 호출로 인한 순환참조 문제와 도메인 주도 설계의 계층별 의존성에 대한 문제를 알게되었습니다.<br>
  #         <mark> ○ 실행</mark> : 
  #           서비스간 호출은 파사드 패턴을 통해 클라이언트와 백엔드를 분리하였습니다.<br>
  #           의존성 문제는, 도메인과 인프라를 분리시키는 작업을 진행하였습니다.<br>
  #           어댑터를 생성하여, service 는 repository interface 를 의존하고 어댑터도 repository interface 를 의존하게 하였습니다.<br>
  #         <mark> ○ 결과</mark> : 
  #           파사드 패턴을 통해 클라이언트는 백엔드에게 제공할 오브젝트에만 집중하고, 백엔드는 비즈니스 로직에 집중할 수 있습니다.<br>
  #           컨트롤러, 서비스 계층의 코드도 간결해지고 객체에서 말하고자 하는 바를 명확히 이해할 수 있습니다.<br>
  #           그리고 도메인과 인프라를 분리시킴으로써 그 어댑터는 SpringDataJpa 등 어떤 인프라가 와도 교체 가능하도록 되었습니다.<br>

  # - title: Skill # Title for the section
  #   layout: list # Type of content section (list/text)
  #   content:
  #     - layout: left
  #       title: Backend
  #       description: |
  #           - Java, Spring Boot, Spring
  #           - Spring MVC, Spring Data JPA
  #           - Eclipse, Intellij
  #     - title: DevOps
  #       description: |
  #           - MySql
  #           - Jenkins, Git
  #     - title: Frontend
  #       description: |
  #           - JSP, Thymeleaf, Java Script
            
# Footer
footer_show_references: true
# references_title: References on request (Override references text)

# Build settings
remote_theme: sproogen/resume-theme

sass:
  sass_dir: _sass
  style: compressed

plugins:
 - jekyll-seo-tag
  